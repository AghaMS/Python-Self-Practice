{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading my own images for DNN personal practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mohammed Agha, November 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "# to iterate through directories\n",
    "import os\n",
    "\n",
    "# to do some image operations\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define the directory and the classes that we need our model to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mohammedagha/Desktop/Python sandbox/pictures\n"
     ]
    }
   ],
   "source": [
    "# Define our working directory\n",
    "DATA_DIR = os.getcwd()\n",
    "print(DATA_DIR)\n",
    "\n",
    "# Define our classes\n",
    "CLASSES = [\"M\", \"NM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an idea for later update\n",
    "# train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets read our images. We will first create an empty list and populate it with the images and the labels.\n",
    "This is an example for a supervised learning classifier, thus we need the labels for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty list \n",
    "train_set_x_orig = []\n",
    "\n",
    "# Define a function to populate the list with each image and its repective label\n",
    "def create_training_data():\n",
    "    for label in CLASSES:\n",
    "        path = os.path.join(DATA_DIR, label)\n",
    "        \n",
    "        Class_num = CLASSES.index(label)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.resize(cv2.imread(os.path.join(path, img)),(96,96))\n",
    "                train_set_x_orig.append([img_array, Class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, we need to shuffle our training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_set_x_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, our training set is of type list, to be able to process it, we need it to be of type np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create two lists, X and Y. X will contain the features while Y will contain the label of the respective image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for feature, label in train_set_x_orig:\n",
    "    X.append(feature)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X).reshape(-1, 96,96,3)\n",
    "Y = np.array(Y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 1 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#for sample in train_set_x_orig:\n",
    " #   print(sample[1])\n",
    "\n",
    "print(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
